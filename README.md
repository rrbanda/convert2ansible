# ğŸ§™â€â™‚ï¸ Convert to Ansible
Convert to Ansible is a smart, expandable Python-based tool that converts [Puppet](https://www.puppet.com) modules or [Chef](https://www.chef.io) recipes into clean, production-grade [Ansible](https://docs.ansible.com) playbooks using Gen AI.

It supports:
- âœ… **Local Ollama** for offline inference
- âœ… **MaaS (Model-as-a-Service)** with `granite-8b-code-instruct-128k` for enterprise-grade generation
- âœ… **Agentic mode with RAG**: combines local **LlamaStack** RAG with remote **MaaS** for high-quality playbooks

---

### ğŸ“ High level Architecture

```text
                        +-------------------+
                        |   User Interface  |
                        | (Streamlit UI App)|
                        +---------+---------+
                                  |
                                  v
                +-----------------------------+
                |       Backend Selector      |
                |  [ollama | maas | agentic]  |
                +--------+----------+---------+
                         |          |
            +------------+          +---------------------+
            |                                     |
   +--------v--------+                   +--------v--------+
   | Ollama Runtime  |                   |  Agentic Backend |
   | (local LLMs)    |                   | using LlamaStack |
   +-----------------+                   +--------+--------+
                                                 |
                                                 v
         +------------------- RAG + MaaS Agent Pipeline --------------------+
         |                                                                  |
         |  LlamaStack Agent (local)                                        |
         |  â””â”€â”€ uses builtin::rag + embeddings (MiniLM, Ollama, etc.)       |
         |                                                                  |
         |  Generation handled by â†’ Granite 8B Code Instruct via MaaS       |
         +------------------------------------------------------------------+
```

---

### ğŸš€ How to Use

Tested with Python 3.11+

#### 1. Clone the repo
```bash
git clone https://github.com/bpaskin/Automation-Code-SorcererX.git
cd Automation-Code-SorcererX
```

#### 2. Setup a virtual environment
```bash
python -m venv .venv
source .venv/bin/activate
```

#### 3. Install dependencies
```bash
pip install -r requirements.txt
```

#### 4. Edit configuration files
- `settings.config` for general paths and default backend
- `config.yaml` for model settings (Ollama, LlamaStack, MaaS)

Example `config.yaml`:

```yaml
default: local

llama_stack:
  local:
    base_url: http://localhost:8321
    model: llama3.2:3b

  maas:
    base_url: https://granite-8b-code-instruct-maas-apicast-production.apps.prod.rhoai.rh-aiservices-bu.com/v1
    model: granite-8b-code-instruct-128k
    api_key: "YOUR_MAAS_API_KEY"
```

---

### ğŸ’» Launch the App (Streamlit UI)

```bash
streamlit run app.py
```

#### Features:
- Upload or browse code files (`.pp`, `.rb`, `.yml`)
- Convert using **Ollama**, **MaaS**, or the **Agentic RAG+MaaS** pipeline
- Output clean Ansible playbooks
- Git repo integration with tag filtering
- Linting (optional extension)

---

### ğŸ“‚ Project Structure

```text
â”œâ”€â”€ app.py                    # Streamlit UI
â”œâ”€â”€ ai_modules/
â”‚   â”œâ”€â”€ ollama_explanator.py
â”‚   â”œâ”€â”€ maas_model.py
â”‚   â””â”€â”€ agentic_model.py     # Agentic backend using LlamaStack + MaaS
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ convert2ansible_agent.py
â”œâ”€â”€ config.yaml
â”œâ”€â”€ settings.config
â”œâ”€â”€ uploads/
â”œâ”€â”€ results/
```

---

### ğŸ§  VectorDB Requirements (Agentic mode)
Ensure your LlamaStack server has these vector DBs created:

- `puppet_docs`
- `chef_docs`

You can preload sample content via the LlamaStack admin or your own ingest script.

---

### ğŸ¤ Contributions

Pull requests, issues, and feature suggestions are welcome!

---

âš ï¸ Disclaimer

   Convert to Ansible is a fun project created for experimenting with the tech stack and evaluating the responses . 
   It is not officially supported by any enterprise.

---
